import argparse
import collections

if __name__ == '__main__':
    parser = argparse.ArgumentParser(
        description="Extract tokens from the original sentencepiece vocab list starting from a list of tokens")

    parser.add_argument("--vocab", help="Vocabulary generated by training sentence piece", required=True)
    parser.add_argument("--terms", help="Files containing the tokens to be matched", required=True)

    args = parser.parse_args()

    vocab_file = args.vocab
    terms_file = args.terms

    vocabulary = {}

    counter = 0
    with open(vocab_file, 'r') as vocab_f:
        for line in vocab_f:
            item = line.rstrip("\n").split("\t")
            vocabulary[item[0]] = item[1]
            counter += 1

    print("Input lenght", counter)
    print("Voc lenght", len(vocabulary.keys()))

    output = {}

    with open(terms_file, 'r') as term_f:
        for term in term_f:
            term = term.rstrip("\n")
            if term.startswith("##"):
                continue
#                 original_term = term.replace("##", "")
            else:
                original_term = '‚ñÅ' + term

            if original_term in vocabulary.keys():
                freq = vocabulary[original_term]

                if freq in output.keys():
                    print("Error, duplicated freq", freq)

                output[int(freq)] = original_term

    od = collections.OrderedDict(sorted(output.items(), reverse=True))
    for freq, term in od.items():
        print(term, "\t", freq)
