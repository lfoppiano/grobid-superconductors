Using TensorFlow backend.
WARNING:tensorflow:From /home/lfoppian0/anaconda3/envs/tensorflow-gpu_env/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING:tensorflow:From /home/lfoppian0/anaconda3/envs/tensorflow-gpu_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
WARNING:tensorflow:From /home/lfoppian0/anaconda3/envs/tensorflow-gpu_env/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
Loading data...
7506 train sequences
834 validation sequences
927 evaluation sequences
embedding_lmdb_path is not specified in the embeddings registry, so the embeddings will be loaded in memory...
loading embeddings...
path: /lustre/group/tdm/Luca/delft/delft/data/embeddings/glove.840B.300d.txt
embeddings loaded for 2196017 words and 300 dimensions

------------------------ fold 0--------------------------------------
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
char_input (InputLayer)         (None, None, 30)     0                                            
__________________________________________________________________________________________________
time_distributed_1 (TimeDistrib (None, None, 30, 25) 3050        char_input[0][0]                 
__________________________________________________________________________________________________
word_input (InputLayer)         (None, None, 300)    0                                            
__________________________________________________________________________________________________
time_distributed_2 (TimeDistrib (None, None, 50)     10200       time_distributed_1[0][0]         
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, None, 350)    0           word_input[0][0]                 
                                                                 time_distributed_2[0][0]         
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, None, 350)    0           concatenate_1[0][0]              
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, None, 200)    360800      dropout_1[0][0]                  
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, None, 200)    0           bidirectional_2[0][0]            
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, None, 100)    20100       dropout_2[0][0]                  
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, None, 18)     1818        dense_1[0][0]                    
__________________________________________________________________________________________________
chain_crf_1 (ChainCRF)          (None, None, 18)     360         dense_2[0][0]                    
==================================================================================================
Total params: 396,328
Trainable params: 396,328
Non-trainable params: 0
__________________________________________________________________________________________________
Epoch 1/100
























































































































































































































































































































































































376/376 [==============================] - 69s 183ms/step - loss: 5.6093
	f1 (micro): 80.41
Epoch 2/100
























































































































































































































































































































































































376/376 [==============================] - 51s 135ms/step - loss: 1.7148
	f1 (micro): 86.58
Epoch 3/100
























































































































































































































































































































































































376/376 [==============================] - 50s 134ms/step - loss: 1.2056
	f1 (micro): 89.76
Epoch 4/100














376/376 [==============================] - 52s 138ms/step - loss: 0.9591
	f1 (micro): 94.48
Epoch 5/100

376/376 [==============================] - 52s 138ms/step - loss: 0.7486
	f1 (micro): 95.03
Epoch 6/100

376/376 [==============================] - 51s 136ms/step - loss: 0.6248
	f1 (micro): 95.27
Epoch 7/100

376/376 [==============================] - 51s 137ms/step - loss: 0.5377
	f1 (micro): 95.29
Epoch 8/100

376/376 [==============================] - 51s 137ms/step - loss: 0.4685
	f1 (micro): 96.08
Epoch 9/100

376/376 [==============================] - 51s 137ms/step - loss: 0.4200
	f1 (micro): 96.08
Epoch 10/100

376/376 [==============================] - 52s 139ms/step - loss: 0.3744
	f1 (micro): 96.46
Epoch 11/100

376/376 [==============================] - 51s 137ms/step - loss: 0.3321
	f1 (micro): 96.15
Epoch 12/100

376/376 [==============================] - 52s 138ms/step - loss: 0.3148
	f1 (micro): 96.41
Epoch 13/100

376/376 [==============================] - 51s 135ms/step - loss: 0.2880
	f1 (micro): 96.33
Epoch 14/100

376/376 [==============================] - 52s 137ms/step - loss: 0.2749
	f1 (micro): 96.79
Epoch 15/100

376/376 [==============================] - 52s 138ms/step - loss: 0.2485
	f1 (micro): 96.92
Epoch 16/100

376/376 [==============================] - 51s 135ms/step - loss: 0.2265
	f1 (micro): 96.67
Epoch 17/100

376/376 [==============================] - 52s 137ms/step - loss: 0.2128
	f1 (micro): 96.42
Epoch 18/100

376/376 [==============================] - 51s 135ms/step - loss: 0.1960
	f1 (micro): 96.75
Epoch 19/100

376/376 [==============================] - 51s 136ms/step - loss: 0.1992
	f1 (micro): 96.75
Epoch 20/100

376/376 [==============================] - 52s 137ms/step - loss: 0.1815
	f1 (micro): 96.80

------------------------ fold 1--------------------------------------
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
char_input (InputLayer)         (None, None, 30)     0                                            
__________________________________________________________________________________________________
time_distributed_3 (TimeDistrib (None, None, 30, 25) 3050        char_input[0][0]                 
__________________________________________________________________________________________________
word_input (InputLayer)         (None, None, 300)    0                                            
__________________________________________________________________________________________________
time_distributed_4 (TimeDistrib (None, None, 50)     10200       time_distributed_3[0][0]         
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, None, 350)    0           word_input[0][0]                 
                                                                 time_distributed_4[0][0]         
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, None, 350)    0           concatenate_2[0][0]              
__________________________________________________________________________________________________
bidirectional_4 (Bidirectional) (None, None, 200)    360800      dropout_3[0][0]                  
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, None, 200)    0           bidirectional_4[0][0]            
__________________________________________________________________________________________________
dense_3 (Dense)                 (None, None, 100)    20100       dropout_4[0][0]                  
__________________________________________________________________________________________________
dense_4 (Dense)                 (None, None, 18)     1818        dense_3[0][0]                    
__________________________________________________________________________________________________
chain_crf_2 (ChainCRF)          (None, None, 18)     360         dense_4[0][0]                    
==================================================================================================
Total params: 396,328
Trainable params: 396,328
Non-trainable params: 0
__________________________________________________________________________________________________
Epoch 1/100

376/376 [==============================] - 60s 161ms/step - loss: 5.7561
	f1 (micro): 78.63
Epoch 2/100

376/376 [==============================] - 51s 135ms/step - loss: 1.7931
	f1 (micro): 89.39
Epoch 3/100

376/376 [==============================] - 52s 139ms/step - loss: 1.2175
	f1 (micro): 93.08
Epoch 4/100

376/376 [==============================] - 50s 133ms/step - loss: 0.9435
	f1 (micro): 94.32
Epoch 5/100

376/376 [==============================] - 51s 136ms/step - loss: 0.7765
	f1 (micro): 95.01
Epoch 6/100

376/376 [==============================] - 51s 136ms/step - loss: 0.6572
	f1 (micro): 95.03
Epoch 7/100

376/376 [==============================] - 52s 137ms/step - loss: 0.5490
	f1 (micro): 95.70
Epoch 8/100

376/376 [==============================] - 51s 137ms/step - loss: 0.4997
	f1 (micro): 95.99
Epoch 9/100

376/376 [==============================] - 52s 138ms/step - loss: 0.4309
	f1 (micro): 95.87
Epoch 10/100

376/376 [==============================] - 50s 134ms/step - loss: 0.3963
	f1 (micro): 96.04
Epoch 11/100

376/376 [==============================] - 52s 137ms/step - loss: 0.3517
	f1 (micro): 96.04
Epoch 12/100

376/376 [==============================] - 51s 135ms/step - loss: 0.3159
	f1 (micro): 96.00
Epoch 13/100

376/376 [==============================] - 51s 135ms/step - loss: 0.2960
	f1 (micro): 96.04
Epoch 14/100

376/376 [==============================] - 51s 137ms/step - loss: 0.2685
	f1 (micro): 96.50
Epoch 15/100

376/376 [==============================] - 52s 139ms/step - loss: 0.2546
	f1 (micro): 96.54
Epoch 16/100

376/376 [==============================] - 51s 137ms/step - loss: 0.2437
	f1 (micro): 96.80
Epoch 17/100

376/376 [==============================] - 51s 135ms/step - loss: 0.2225
	f1 (micro): 96.63
Epoch 18/100

376/376 [==============================] - 50s 134ms/step - loss: 0.2147
	f1 (micro): 97.04
Epoch 19/100

376/376 [==============================] - 50s 132ms/step - loss: 0.2027
	f1 (micro): 96.50
Epoch 20/100

376/376 [==============================] - 51s 136ms/step - loss: 0.1862
	f1 (micro): 96.71
Epoch 21/100

376/376 [==============================] - 51s 135ms/step - loss: 0.1859
	f1 (micro): 96.67
Epoch 22/100

376/376 [==============================] - 52s 137ms/step - loss: 0.1712
	f1 (micro): 96.59
Epoch 23/100

376/376 [==============================] - 49s 131ms/step - loss: 0.1515
	f1 (micro): 96.33

------------------------ fold 2--------------------------------------
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
char_input (InputLayer)         (None, None, 30)     0                                            
__________________________________________________________________________________________________
time_distributed_5 (TimeDistrib (None, None, 30, 25) 3050        char_input[0][0]                 
__________________________________________________________________________________________________
word_input (InputLayer)         (None, None, 300)    0                                            
__________________________________________________________________________________________________
time_distributed_6 (TimeDistrib (None, None, 50)     10200       time_distributed_5[0][0]         
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, None, 350)    0           word_input[0][0]                 
                                                                 time_distributed_6[0][0]         
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, None, 350)    0           concatenate_3[0][0]              
__________________________________________________________________________________________________
bidirectional_6 (Bidirectional) (None, None, 200)    360800      dropout_5[0][0]                  
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, None, 200)    0           bidirectional_6[0][0]            
__________________________________________________________________________________________________
dense_5 (Dense)                 (None, None, 100)    20100       dropout_6[0][0]                  
__________________________________________________________________________________________________
dense_6 (Dense)                 (None, None, 18)     1818        dense_5[0][0]                    
__________________________________________________________________________________________________
chain_crf_3 (ChainCRF)          (None, None, 18)     360         dense_6[0][0]                    
==================================================================================================
Total params: 396,328
Trainable params: 396,328
Non-trainable params: 0
__________________________________________________________________________________________________
Epoch 1/100

376/376 [==============================] - 60s 160ms/step - loss: 6.5412
	f1 (micro): 78.90
Epoch 2/100

376/376 [==============================] - 51s 136ms/step - loss: 1.8196
	f1 (micro): 86.81
Epoch 3/100

376/376 [==============================] - 51s 135ms/step - loss: 1.3164
	f1 (micro): 91.65
Epoch 4/100

376/376 [==============================] - 51s 135ms/step - loss: 0.9891
	f1 (micro): 93.98
Epoch 5/100

376/376 [==============================] - 51s 137ms/step - loss: 0.8000
	f1 (micro): 94.75
Epoch 6/100

376/376 [==============================] - 51s 137ms/step - loss: 0.6683
	f1 (micro): 95.08
Epoch 7/100

376/376 [==============================] - 51s 136ms/step - loss: 0.5657
	f1 (micro): 95.25
Epoch 8/100

376/376 [==============================] - 50s 132ms/step - loss: 0.5023
	f1 (micro): 95.53
Epoch 9/100

376/376 [==============================] - 51s 135ms/step - loss: 0.4488
	f1 (micro): 95.53
Epoch 10/100

376/376 [==============================] - 50s 132ms/step - loss: 0.4019
	f1 (micro): 96.25
Epoch 11/100

376/376 [==============================] - 50s 132ms/step - loss: 0.3660
	f1 (micro): 95.87
Epoch 12/100

376/376 [==============================] - 50s 133ms/step - loss: 0.3413
	f1 (micro): 95.79
Epoch 13/100

376/376 [==============================] - 50s 134ms/step - loss: 0.2911
	f1 (micro): 95.58
Epoch 14/100

376/376 [==============================] - 50s 133ms/step - loss: 0.2895
	f1 (micro): 96.08
Epoch 15/100

376/376 [==============================] - 50s 132ms/step - loss: 0.2454
	f1 (micro): 96.20

------------------------ fold 3--------------------------------------
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
char_input (InputLayer)         (None, None, 30)     0                                            
__________________________________________________________________________________________________
time_distributed_7 (TimeDistrib (None, None, 30, 25) 3050        char_input[0][0]                 
__________________________________________________________________________________________________
word_input (InputLayer)         (None, None, 300)    0                                            
__________________________________________________________________________________________________
time_distributed_8 (TimeDistrib (None, None, 50)     10200       time_distributed_7[0][0]         
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, None, 350)    0           word_input[0][0]                 
                                                                 time_distributed_8[0][0]         
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, None, 350)    0           concatenate_4[0][0]              
__________________________________________________________________________________________________
bidirectional_8 (Bidirectional) (None, None, 200)    360800      dropout_7[0][0]                  
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, None, 200)    0           bidirectional_8[0][0]            
__________________________________________________________________________________________________
dense_7 (Dense)                 (None, None, 100)    20100       dropout_8[0][0]                  
__________________________________________________________________________________________________
dense_8 (Dense)                 (None, None, 18)     1818        dense_7[0][0]                    
__________________________________________________________________________________________________
chain_crf_4 (ChainCRF)          (None, None, 18)     360         dense_8[0][0]                    
==================================================================================================
Total params: 396,328
Trainable params: 396,328
Non-trainable params: 0
__________________________________________________________________________________________________
Epoch 1/100

376/376 [==============================] - 60s 158ms/step - loss: 5.8047
	f1 (micro): 80.41
Epoch 2/100

376/376 [==============================] - 51s 136ms/step - loss: 1.6791
	f1 (micro): 87.70
Epoch 3/100

376/376 [==============================] - 51s 135ms/step - loss: 1.1868
	f1 (micro): 92.90
Epoch 4/100

376/376 [==============================] - 50s 133ms/step - loss: 0.9022
	f1 (micro): 93.60
Epoch 5/100

376/376 [==============================] - 50s 134ms/step - loss: 0.7170
	f1 (micro): 95.11
Epoch 6/100

376/376 [==============================] - 50s 133ms/step - loss: 0.6251
	f1 (micro): 95.12
Epoch 7/100

376/376 [==============================] - 50s 133ms/step - loss: 0.5434
	f1 (micro): 95.28
Epoch 8/100

376/376 [==============================] - 50s 134ms/step - loss: 0.4769
	f1 (micro): 95.77
Epoch 9/100

376/376 [==============================] - 50s 133ms/step - loss: 0.4335
	f1 (micro): 95.92
Epoch 10/100

376/376 [==============================] - 51s 135ms/step - loss: 0.3792
	f1 (micro): 95.79
Epoch 11/100

376/376 [==============================] - 52s 138ms/step - loss: 0.3540
	f1 (micro): 95.96
Epoch 12/100

376/376 [==============================] - 50s 133ms/step - loss: 0.3169
	f1 (micro): 96.37
Epoch 13/100

376/376 [==============================] - 52s 138ms/step - loss: 0.2946
	f1 (micro): 96.37
Epoch 14/100

376/376 [==============================] - 51s 136ms/step - loss: 0.2635
	f1 (micro): 96.25
Epoch 15/100

376/376 [==============================] - 51s 135ms/step - loss: 0.2504
	f1 (micro): 96.62
Epoch 16/100

376/376 [==============================] - 52s 137ms/step - loss: 0.2408
	f1 (micro): 96.42
Epoch 17/100

376/376 [==============================] - 51s 137ms/step - loss: 0.2339
	f1 (micro): 96.71
Epoch 18/100

376/376 [==============================] - 52s 139ms/step - loss: 0.2060
	f1 (micro): 97.00
Epoch 19/100

376/376 [==============================] - 52s 139ms/step - loss: 0.1907
	f1 (micro): 96.29
Epoch 20/100

376/376 [==============================] - 51s 136ms/step - loss: 0.1822
	f1 (micro): 96.71
Epoch 21/100

376/376 [==============================] - 52s 138ms/step - loss: 0.1845
	f1 (micro): 96.75
Epoch 22/100

376/376 [==============================] - 51s 137ms/step - loss: 0.1862
	f1 (micro): 96.84
Epoch 23/100

376/376 [==============================] - 52s 137ms/step - loss: 0.1558
	f1 (micro): 96.59

------------------------ fold 4--------------------------------------
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
char_input (InputLayer)         (None, None, 30)     0                                            
__________________________________________________________________________________________________
time_distributed_9 (TimeDistrib (None, None, 30, 25) 3050        char_input[0][0]                 
__________________________________________________________________________________________________
word_input (InputLayer)         (None, None, 300)    0                                            
__________________________________________________________________________________________________
time_distributed_10 (TimeDistri (None, None, 50)     10200       time_distributed_9[0][0]         
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, None, 350)    0           word_input[0][0]                 
                                                                 time_distributed_10[0][0]        
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, None, 350)    0           concatenate_5[0][0]              
__________________________________________________________________________________________________
bidirectional_10 (Bidirectional (None, None, 200)    360800      dropout_9[0][0]                  
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, None, 200)    0           bidirectional_10[0][0]           
__________________________________________________________________________________________________
dense_9 (Dense)                 (None, None, 100)    20100       dropout_10[0][0]                 
__________________________________________________________________________________________________
dense_10 (Dense)                (None, None, 18)     1818        dense_9[0][0]                    
__________________________________________________________________________________________________
chain_crf_5 (ChainCRF)          (None, None, 18)     360         dense_10[0][0]                   
==================================================================================================
Total params: 396,328
Trainable params: 396,328
Non-trainable params: 0
__________________________________________________________________________________________________
Epoch 1/100

376/376 [==============================] - 61s 162ms/step - loss: 6.0581
	f1 (micro): 79.85
Epoch 2/100

376/376 [==============================] - 51s 135ms/step - loss: 1.7658
	f1 (micro): 86.64
Epoch 3/100

376/376 [==============================] - 51s 137ms/step - loss: 1.2442
	f1 (micro): 92.64
Epoch 4/100

376/376 [==============================] - 52s 138ms/step - loss: 0.9583
	f1 (micro): 94.36
Epoch 5/100

376/376 [==============================] - 51s 137ms/step - loss: 0.7901
	f1 (micro): 94.58
Epoch 6/100

376/376 [==============================] - 51s 135ms/step - loss: 0.6475
	f1 (micro): 95.36
Epoch 7/100

376/376 [==============================] - 51s 134ms/step - loss: 0.5649
	f1 (micro): 95.65
Epoch 8/100

376/376 [==============================] - 50s 133ms/step - loss: 0.4902
	f1 (micro): 95.91
Epoch 9/100

376/376 [==============================] - 52s 138ms/step - loss: 0.4344
	f1 (micro): 95.48
Epoch 10/100

376/376 [==============================] - 51s 135ms/step - loss: 0.3911
	f1 (micro): 96.37
Epoch 11/100

376/376 [==============================] - 50s 132ms/step - loss: 0.3464
	f1 (micro): 96.04
Epoch 12/100

376/376 [==============================] - 50s 133ms/step - loss: 0.3220
	f1 (micro): 96.08
Epoch 13/100

376/376 [==============================] - 50s 132ms/step - loss: 0.3011
	f1 (micro): 95.70
Epoch 14/100

376/376 [==============================] - 50s 132ms/step - loss: 0.2808
	f1 (micro): 96.24
Epoch 15/100

376/376 [==============================] - 50s 134ms/step - loss: 0.2595
	f1 (micro): 96.21

------------------------ fold 5--------------------------------------
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
char_input (InputLayer)         (None, None, 30)     0                                            
__________________________________________________________________________________________________
time_distributed_11 (TimeDistri (None, None, 30, 25) 3050        char_input[0][0]                 
__________________________________________________________________________________________________
word_input (InputLayer)         (None, None, 300)    0                                            
__________________________________________________________________________________________________
time_distributed_12 (TimeDistri (None, None, 50)     10200       time_distributed_11[0][0]        
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, None, 350)    0           word_input[0][0]                 
                                                                 time_distributed_12[0][0]        
__________________________________________________________________________________________________
dropout_11 (Dropout)            (None, None, 350)    0           concatenate_6[0][0]              
__________________________________________________________________________________________________
bidirectional_12 (Bidirectional (None, None, 200)    360800      dropout_11[0][0]                 
__________________________________________________________________________________________________
dropout_12 (Dropout)            (None, None, 200)    0           bidirectional_12[0][0]           
__________________________________________________________________________________________________
dense_11 (Dense)                (None, None, 100)    20100       dropout_12[0][0]                 
__________________________________________________________________________________________________
dense_12 (Dense)                (None, None, 18)     1818        dense_11[0][0]                   
__________________________________________________________________________________________________
chain_crf_6 (ChainCRF)          (None, None, 18)     360         dense_12[0][0]                   
==================================================================================================
Total params: 396,328
Trainable params: 396,328
Non-trainable params: 0
__________________________________________________________________________________________________
Epoch 1/100

376/376 [==============================] - 61s 163ms/step - loss: 5.5240
	f1 (micro): 81.26
Epoch 2/100

376/376 [==============================] - 51s 136ms/step - loss: 1.7043
	f1 (micro): 90.22
Epoch 3/100

376/376 [==============================] - 50s 133ms/step - loss: 1.1776
	f1 (micro): 92.59
Epoch 4/100

376/376 [==============================] - 50s 134ms/step - loss: 0.9045
	f1 (micro): 94.12
Epoch 5/100

376/376 [==============================] - 51s 137ms/step - loss: 0.7367
	f1 (micro): 95.02
Epoch 6/100

376/376 [==============================] - 51s 137ms/step - loss: 0.6395
	f1 (micro): 95.17
Epoch 7/100

376/376 [==============================] - 51s 136ms/step - loss: 0.5276
	f1 (micro): 95.79
Epoch 8/100

376/376 [==============================] - 51s 136ms/step - loss: 0.4804
	f1 (micro): 95.83
Epoch 9/100

376/376 [==============================] - 51s 136ms/step - loss: 0.4095
	f1 (micro): 95.28
Epoch 10/100

376/376 [==============================] - 52s 138ms/step - loss: 0.3774
	f1 (micro): 95.87
Epoch 11/100

376/376 [==============================] - 51s 135ms/step - loss: 0.3360
	f1 (micro): 95.95
Epoch 12/100

376/376 [==============================] - 52s 138ms/step - loss: 0.3138
	f1 (micro): 96.21
Epoch 13/100

376/376 [==============================] - 52s 138ms/step - loss: 0.3010
	f1 (micro): 96.42
Epoch 14/100

376/376 [==============================] - 51s 136ms/step - loss: 0.2675
	f1 (micro): 96.16
Epoch 15/100

376/376 [==============================] - 51s 136ms/step - loss: 0.2465
	f1 (micro): 96.46
Epoch 16/100

376/376 [==============================] - 51s 136ms/step - loss: 0.2269
	f1 (micro): 96.13
Epoch 17/100

376/376 [==============================] - 51s 136ms/step - loss: 0.2098
	f1 (micro): 96.55
Epoch 18/100

376/376 [==============================] - 51s 135ms/step - loss: 0.2035
	f1 (micro): 96.42
Epoch 19/100

376/376 [==============================] - 50s 134ms/step - loss: 0.2082
	f1 (micro): 96.34
Epoch 20/100

376/376 [==============================] - 50s 134ms/step - loss: 0.1837
	f1 (micro): 96.38
Epoch 21/100

376/376 [==============================] - 50s 134ms/step - loss: 0.1818
	f1 (micro): 96.84
Epoch 22/100

376/376 [==============================] - 51s 136ms/step - loss: 0.1759
	f1 (micro): 96.92
Epoch 23/100

376/376 [==============================] - 50s 134ms/step - loss: 0.1420
	f1 (micro): 96.92
Epoch 24/100

376/376 [==============================] - 50s 134ms/step - loss: 0.1471
	f1 (micro): 96.63
Epoch 25/100

376/376 [==============================] - 52s 138ms/step - loss: 0.1412
	f1 (micro): 96.62
Epoch 26/100

376/376 [==============================] - 51s 136ms/step - loss: 0.1445
	f1 (micro): 96.63
Epoch 27/100

376/376 [==============================] - 50s 133ms/step - loss: 0.1276
	f1 (micro): 96.71

------------------------ fold 6--------------------------------------
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
char_input (InputLayer)         (None, None, 30)     0                                            
__________________________________________________________________________________________________
time_distributed_13 (TimeDistri (None, None, 30, 25) 3050        char_input[0][0]                 
__________________________________________________________________________________________________
word_input (InputLayer)         (None, None, 300)    0                                            
__________________________________________________________________________________________________
time_distributed_14 (TimeDistri (None, None, 50)     10200       time_distributed_13[0][0]        
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, None, 350)    0           word_input[0][0]                 
                                                                 time_distributed_14[0][0]        
__________________________________________________________________________________________________
dropout_13 (Dropout)            (None, None, 350)    0           concatenate_7[0][0]              
__________________________________________________________________________________________________
bidirectional_14 (Bidirectional (None, None, 200)    360800      dropout_13[0][0]                 
__________________________________________________________________________________________________
dropout_14 (Dropout)            (None, None, 200)    0           bidirectional_14[0][0]           
__________________________________________________________________________________________________
dense_13 (Dense)                (None, None, 100)    20100       dropout_14[0][0]                 
__________________________________________________________________________________________________
dense_14 (Dense)                (None, None, 18)     1818        dense_13[0][0]                   
__________________________________________________________________________________________________
chain_crf_7 (ChainCRF)          (None, None, 18)     360         dense_14[0][0]                   
==================================================================================================
Total params: 396,328
Trainable params: 396,328
Non-trainable params: 0
__________________________________________________________________________________________________
Epoch 1/100

376/376 [==============================] - 61s 163ms/step - loss: 5.8859
	f1 (micro): 80.45
Epoch 2/100

376/376 [==============================] - 50s 134ms/step - loss: 1.7563
	f1 (micro): 89.75
Epoch 3/100

376/376 [==============================] - 50s 133ms/step - loss: 1.1939
	f1 (micro): 93.12
Epoch 4/100

376/376 [==============================] - 51s 135ms/step - loss: 0.9321
	f1 (micro): 94.45
Epoch 5/100

376/376 [==============================] - 52s 138ms/step - loss: 0.7428
	f1 (micro): 94.35
Epoch 6/100

376/376 [==============================] - 51s 136ms/step - loss: 0.6167
	f1 (micro): 94.94
Epoch 7/100

376/376 [==============================] - 51s 135ms/step - loss: 0.5467
	f1 (micro): 95.66
Epoch 8/100

376/376 [==============================] - 50s 133ms/step - loss: 0.4760
	f1 (micro): 95.61
Epoch 9/100

376/376 [==============================] - 50s 133ms/step - loss: 0.4076
	f1 (micro): 96.12
Epoch 10/100

376/376 [==============================] - 50s 133ms/step - loss: 0.3868
	f1 (micro): 95.87
Epoch 11/100

376/376 [==============================] - 50s 133ms/step - loss: 0.3410
	f1 (micro): 96.12
Epoch 12/100

376/376 [==============================] - 49s 131ms/step - loss: 0.3081
	f1 (micro): 96.55
Epoch 13/100

376/376 [==============================] - 50s 134ms/step - loss: 0.2859
	f1 (micro): 96.17
Epoch 14/100

376/376 [==============================] - 50s 134ms/step - loss: 0.2718
	f1 (micro): 96.08
Epoch 15/100

376/376 [==============================] - 50s 132ms/step - loss: 0.2515
	f1 (micro): 96.33
Epoch 16/100

376/376 [==============================] - 50s 134ms/step - loss: 0.2289
	f1 (micro): 96.63
Epoch 17/100

376/376 [==============================] - 50s 134ms/step - loss: 0.2169
	f1 (micro): 97.04
Epoch 18/100

376/376 [==============================] - 50s 133ms/step - loss: 0.2080
	f1 (micro): 95.83
Epoch 19/100

376/376 [==============================] - 50s 132ms/step - loss: 0.1898
	f1 (micro): 96.55
Epoch 20/100

376/376 [==============================] - 50s 132ms/step - loss: 0.1822
	f1 (micro): 96.88
Epoch 21/100

376/376 [==============================] - 50s 132ms/step - loss: 0.1809
	f1 (micro): 96.88
Epoch 22/100

376/376 [==============================] - 50s 133ms/step - loss: 0.1661
	f1 (micro): 96.59

------------------------ fold 7--------------------------------------
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
char_input (InputLayer)         (None, None, 30)     0                                            
__________________________________________________________________________________________________
time_distributed_15 (TimeDistri (None, None, 30, 25) 3050        char_input[0][0]                 
__________________________________________________________________________________________________
word_input (InputLayer)         (None, None, 300)    0                                            
__________________________________________________________________________________________________
time_distributed_16 (TimeDistri (None, None, 50)     10200       time_distributed_15[0][0]        
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, None, 350)    0           word_input[0][0]                 
                                                                 time_distributed_16[0][0]        
__________________________________________________________________________________________________
dropout_15 (Dropout)            (None, None, 350)    0           concatenate_8[0][0]              
__________________________________________________________________________________________________
bidirectional_16 (Bidirectional (None, None, 200)    360800      dropout_15[0][0]                 
__________________________________________________________________________________________________
dropout_16 (Dropout)            (None, None, 200)    0           bidirectional_16[0][0]           
__________________________________________________________________________________________________
dense_15 (Dense)                (None, None, 100)    20100       dropout_16[0][0]                 
__________________________________________________________________________________________________
dense_16 (Dense)                (None, None, 18)     1818        dense_15[0][0]                   
__________________________________________________________________________________________________
chain_crf_8 (ChainCRF)          (None, None, 18)     360         dense_16[0][0]                   
==================================================================================================
Total params: 396,328
Trainable params: 396,328
Non-trainable params: 0
__________________________________________________________________________________________________
Epoch 1/100

376/376 [==============================] - 61s 163ms/step - loss: 5.9686
	f1 (micro): 81.05
Epoch 2/100

376/376 [==============================] - 50s 134ms/step - loss: 1.7408
	f1 (micro): 88.55
Epoch 3/100

376/376 [==============================] - 51s 136ms/step - loss: 1.2481
	f1 (micro): 93.41
Epoch 4/100

376/376 [==============================] - 51s 137ms/step - loss: 0.9139
	f1 (micro): 94.20
Epoch 5/100

376/376 [==============================] - 52s 138ms/step - loss: 0.7400
	f1 (micro): 95.03
Epoch 6/100

376/376 [==============================] - 51s 135ms/step - loss: 0.6263
	f1 (micro): 95.17
Epoch 7/100

376/376 [==============================] - 51s 135ms/step - loss: 0.5391
	f1 (micro): 95.40
Epoch 8/100

376/376 [==============================] - 51s 137ms/step - loss: 0.4580
	f1 (micro): 95.92
Epoch 9/100

376/376 [==============================] - 52s 138ms/step - loss: 0.4251
	f1 (micro): 95.67
Epoch 10/100

376/376 [==============================] - 51s 136ms/step - loss: 0.3926
	f1 (micro): 96.00
Epoch 11/100

376/376 [==============================] - 51s 136ms/step - loss: 0.3479
	f1 (micro): 96.04
Epoch 12/100

376/376 [==============================] - 50s 133ms/step - loss: 0.3146
	f1 (micro): 96.37
Epoch 13/100

376/376 [==============================] - 51s 136ms/step - loss: 0.3051
	f1 (micro): 96.33
Epoch 14/100

376/376 [==============================] - 50s 132ms/step - loss: 0.2637
	f1 (micro): 96.50
Epoch 15/100

376/376 [==============================] - 50s 133ms/step - loss: 0.2605
	f1 (micro): 96.67
Epoch 16/100

376/376 [==============================] - 51s 135ms/step - loss: 0.2271
	f1 (micro): 96.46
Epoch 17/100

376/376 [==============================] - 51s 135ms/step - loss: 0.2211
	f1 (micro): 96.42
Epoch 18/100

376/376 [==============================] - 51s 135ms/step - loss: 0.2036
	f1 (micro): 96.37
Epoch 19/100

376/376 [==============================] - 51s 135ms/step - loss: 0.2017
	f1 (micro): 96.22
Epoch 20/100

376/376 [==============================] - 50s 134ms/step - loss: 0.1867
	f1 (micro): 96.50

------------------------ fold 8--------------------------------------
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
char_input (InputLayer)         (None, None, 30)     0                                            
__________________________________________________________________________________________________
time_distributed_17 (TimeDistri (None, None, 30, 25) 3050        char_input[0][0]                 
__________________________________________________________________________________________________
word_input (InputLayer)         (None, None, 300)    0                                            
__________________________________________________________________________________________________
time_distributed_18 (TimeDistri (None, None, 50)     10200       time_distributed_17[0][0]        
__________________________________________________________________________________________________
concatenate_9 (Concatenate)     (None, None, 350)    0           word_input[0][0]                 
                                                                 time_distributed_18[0][0]        
__________________________________________________________________________________________________
dropout_17 (Dropout)            (None, None, 350)    0           concatenate_9[0][0]              
__________________________________________________________________________________________________
bidirectional_18 (Bidirectional (None, None, 200)    360800      dropout_17[0][0]                 
__________________________________________________________________________________________________
dropout_18 (Dropout)            (None, None, 200)    0           bidirectional_18[0][0]           
__________________________________________________________________________________________________
dense_17 (Dense)                (None, None, 100)    20100       dropout_18[0][0]                 
__________________________________________________________________________________________________
dense_18 (Dense)                (None, None, 18)     1818        dense_17[0][0]                   
__________________________________________________________________________________________________
chain_crf_9 (ChainCRF)          (None, None, 18)     360         dense_18[0][0]                   
==================================================================================================
Total params: 396,328
Trainable params: 396,328
Non-trainable params: 0
__________________________________________________________________________________________________
Epoch 1/100

376/376 [==============================] - 64s 169ms/step - loss: 5.7749
	f1 (micro): 79.95
Epoch 2/100

376/376 [==============================] - 52s 137ms/step - loss: 1.7401
	f1 (micro): 88.17
Epoch 3/100

376/376 [==============================] - 50s 133ms/step - loss: 1.2350
	f1 (micro): 93.58
Epoch 4/100

376/376 [==============================] - 51s 135ms/step - loss: 0.9397
	f1 (micro): 94.46
Epoch 5/100

376/376 [==============================] - 50s 133ms/step - loss: 0.7713
	f1 (micro): 95.32
Epoch 6/100

376/376 [==============================] - 50s 133ms/step - loss: 0.6350
	f1 (micro): 95.44
Epoch 7/100

376/376 [==============================] - 50s 132ms/step - loss: 0.5335
	f1 (micro): 95.57
Epoch 8/100

376/376 [==============================] - 51s 135ms/step - loss: 0.4773
	f1 (micro): 96.28
Epoch 9/100

376/376 [==============================] - 50s 133ms/step - loss: 0.4382
	f1 (micro): 95.91
Epoch 10/100

376/376 [==============================] - 50s 133ms/step - loss: 0.3899
	f1 (micro): 96.53
Epoch 11/100

376/376 [==============================] - 50s 133ms/step - loss: 0.3506
	f1 (micro): 96.75
Epoch 12/100

376/376 [==============================] - 50s 132ms/step - loss: 0.3179
	f1 (micro): 96.46
Epoch 13/100

376/376 [==============================] - 51s 135ms/step - loss: 0.2851
	f1 (micro): 96.96
Epoch 14/100

376/376 [==============================] - 50s 134ms/step - loss: 0.2606
	f1 (micro): 96.91
Epoch 15/100

376/376 [==============================] - 51s 136ms/step - loss: 0.2585
	f1 (micro): 96.71
Epoch 16/100

376/376 [==============================] - 51s 137ms/step - loss: 0.2376
	f1 (micro): 96.62
Epoch 17/100

376/376 [==============================] - 50s 133ms/step - loss: 0.2024
	f1 (micro): 96.54
Epoch 18/100

376/376 [==============================] - 51s 137ms/step - loss: 0.2000
	f1 (micro): 96.88

------------------------ fold 9--------------------------------------
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
char_input (InputLayer)         (None, None, 30)     0                                            
__________________________________________________________________________________________________
time_distributed_19 (TimeDistri (None, None, 30, 25) 3050        char_input[0][0]                 
__________________________________________________________________________________________________
word_input (InputLayer)         (None, None, 300)    0                                            
__________________________________________________________________________________________________
time_distributed_20 (TimeDistri (None, None, 50)     10200       time_distributed_19[0][0]        
__________________________________________________________________________________________________
concatenate_10 (Concatenate)    (None, None, 350)    0           word_input[0][0]                 
                                                                 time_distributed_20[0][0]        
__________________________________________________________________________________________________
dropout_19 (Dropout)            (None, None, 350)    0           concatenate_10[0][0]             
__________________________________________________________________________________________________
bidirectional_20 (Bidirectional (None, None, 200)    360800      dropout_19[0][0]                 
__________________________________________________________________________________________________
dropout_20 (Dropout)            (None, None, 200)    0           bidirectional_20[0][0]           
__________________________________________________________________________________________________
dense_19 (Dense)                (None, None, 100)    20100       dropout_20[0][0]                 
__________________________________________________________________________________________________
dense_20 (Dense)                (None, None, 18)     1818        dense_19[0][0]                   
__________________________________________________________________________________________________
chain_crf_10 (ChainCRF)         (None, None, 18)     360         dense_20[0][0]                   
==================================================================================================
Total params: 396,328
Trainable params: 396,328
Non-trainable params: 0
__________________________________________________________________________________________________
Epoch 1/100

376/376 [==============================] - 69s 183ms/step - loss: 5.6960
	f1 (micro): 80.46
Epoch 2/100

376/376 [==============================] - 52s 138ms/step - loss: 1.7941
	f1 (micro): 87.39
Epoch 3/100

376/376 [==============================] - 52s 138ms/step - loss: 1.2400
	f1 (micro): 90.56
Epoch 4/100

376/376 [==============================] - 51s 136ms/step - loss: 0.9675
	f1 (micro): 91.85
Epoch 5/100

376/376 [==============================] - 50s 134ms/step - loss: 0.7701
	f1 (micro): 95.08
Epoch 6/100

376/376 [==============================] - 51s 137ms/step - loss: 0.6507
	f1 (micro): 95.58
Epoch 7/100

376/376 [==============================] - 51s 137ms/step - loss: 0.5562
	f1 (micro): 95.46
Epoch 8/100

376/376 [==============================] - 51s 136ms/step - loss: 0.5028
	f1 (micro): 95.45
Epoch 9/100

376/376 [==============================] - 51s 135ms/step - loss: 0.4353
	f1 (micro): 96.05
Epoch 10/100

376/376 [==============================] - 52s 137ms/step - loss: 0.3749
	f1 (micro): 95.62
Epoch 11/100

376/376 [==============================] - 52s 138ms/step - loss: 0.3662
	f1 (micro): 96.01
Epoch 12/100

376/376 [==============================] - 52s 138ms/step - loss: 0.3025
	f1 (micro): 95.87
Epoch 13/100

376/376 [==============================] - 52s 139ms/step - loss: 0.2940
	f1 (micro): 95.87
Epoch 14/100

376/376 [==============================] - 52s 138ms/step - loss: 0.2711
	f1 (micro): 96.04
training runtime: 10636.212 seconds 

Evaluation:

------------------------ fold 0 --------------------------------------
	f1 (micro): 96.16
                  precision    recall  f1-score   support

        <doping>     0.8667    0.8966    0.8814        87
   <fabrication>     0.1429    0.3333    0.2000         3
       <formula>     0.9730    0.9715    0.9722       631
          <name>     0.9718    0.9609    0.9663       179
         <shape>     0.9726    0.9467    0.9595        75
     <substrate>     0.5714    1.0000    0.7273         4
         <value>     0.9557    0.9604    0.9580       202
      <variable>     0.9899    0.9899    0.9899       198

all (micro avg.)     0.9596    0.9637    0.9616      1379


------------------------ fold 1 --------------------------------------
	f1 (micro): 95.99
                  precision    recall  f1-score   support

        <doping>     0.8152    0.8621    0.8380        87
   <fabrication>     0.0000    0.0000    0.0000         3
       <formula>     0.9686    0.9778    0.9732       631
          <name>     0.9774    0.9665    0.9719       179
         <shape>     0.9467    0.9467    0.9467        75
     <substrate>     0.8000    1.0000    0.8889         4
         <value>     0.9600    0.9505    0.9552       202
      <variable>     0.9899    0.9899    0.9899       198

all (micro avg.)     0.9568    0.9630    0.9599      1379


------------------------ fold 2 --------------------------------------
	f1 (micro): 95.70
                  precision    recall  f1-score   support

        <doping>     0.8764    0.8966    0.8864        87
   <fabrication>     0.2000    0.3333    0.2500         3
       <formula>     0.9625    0.9762    0.9693       631
          <name>     0.9543    0.9330    0.9435       179
         <shape>     0.9861    0.9467    0.9660        75
     <substrate>     0.5000    1.0000    0.6667         4
         <value>     0.9458    0.9505    0.9481       202
      <variable>     0.9899    0.9899    0.9899       198

all (micro avg.)     0.9532    0.9608    0.9570      1379


------------------------ fold 3 --------------------------------------
	f1 (micro): 96.64
                  precision    recall  f1-score   support

        <doping>     0.8125    0.8966    0.8525        87
   <fabrication>     0.3333    0.3333    0.3333         3
       <formula>     0.9809    0.9762    0.9786       631
          <name>     0.9722    0.9777    0.9749       179
         <shape>     0.9730    0.9600    0.9664        75
     <substrate>     0.6667    1.0000    0.8000         4
         <value>     0.9606    0.9653    0.9630       202
      <variable>     0.9899    0.9899    0.9899       198

all (micro avg.)     0.9633    0.9695    0.9664      1379


------------------------ fold 4 --------------------------------------
	f1 (micro): 95.85
                  precision    recall  f1-score   support

        <doping>     0.8721    0.8621    0.8671        87
   <fabrication>     0.0667    0.3333    0.1111         3
       <formula>     0.9731    0.9762    0.9747       631
          <name>     0.9718    0.9609    0.9663       179
         <shape>     0.9595    0.9467    0.9530        75
     <substrate>     0.8000    1.0000    0.8889         4
         <value>     0.9461    0.9554    0.9507       202
      <variable>     0.9899    0.9899    0.9899       198

all (micro avg.)     0.9540    0.9630    0.9585      1379


------------------------ fold 5 --------------------------------------
	f1 (micro): 96.24
                  precision    recall  f1-score   support

        <doping>     0.8191    0.8851    0.8508        87
   <fabrication>     0.0000    0.0000    0.0000         3
       <formula>     0.9793    0.9762    0.9778       631
          <name>     0.9505    0.9665    0.9584       179
         <shape>     0.9595    0.9467    0.9530        75
     <substrate>     1.0000    1.0000    1.0000         4
         <value>     0.9510    0.9604    0.9557       202
      <variable>     0.9899    0.9899    0.9899       198

all (micro avg.)     0.9596    0.9652    0.9624      1379


------------------------ fold 6 --------------------------------------
	f1 (micro): 96.07
                  precision    recall  f1-score   support

        <doping>     0.8851    0.8851    0.8851        87
   <fabrication>     0.0000    0.0000    0.0000         3
       <formula>     0.9746    0.9746    0.9746       631
          <name>     0.9358    0.9777    0.9563       179
         <shape>     0.9221    0.9467    0.9342        75
     <substrate>     0.5714    1.0000    0.7273         4
         <value>     0.9606    0.9653    0.9630       202
      <variable>     0.9899    0.9899    0.9899       198

all (micro avg.)     0.9549    0.9666    0.9607      1379


------------------------ fold 7 --------------------------------------
	f1 (micro): 96.17
                  precision    recall  f1-score   support

        <doping>     0.8444    0.8736    0.8588        87
   <fabrication>     0.0000    0.0000    0.0000         3
       <formula>     0.9731    0.9731    0.9731       631
          <name>     0.9670    0.9832    0.9751       179
         <shape>     0.9726    0.9467    0.9595        75
     <substrate>     0.5000    0.7500    0.6000         4
         <value>     0.9557    0.9604    0.9580       202
      <variable>     0.9849    0.9899    0.9874       198

all (micro avg.)     0.9589    0.9645    0.9617      1379


------------------------ fold 8 --------------------------------------
	f1 (micro): 96.38
                  precision    recall  f1-score   support

        <doping>     0.8444    0.8736    0.8588        87
   <fabrication>     0.0000    0.0000    0.0000         3
       <formula>     0.9762    0.9746    0.9754       631
          <name>     0.9669    0.9777    0.9722       179
         <shape>     0.9730    0.9600    0.9664        75
     <substrate>     0.5000    1.0000    0.6667         4
         <value>     0.9559    0.9653    0.9606       202
      <variable>     0.9899    0.9899    0.9899       198

all (micro avg.)     0.9611    0.9666    0.9638      1379


------------------------ fold 9 --------------------------------------
	f1 (micro): 95.70
                  precision    recall  f1-score   support

        <doping>     0.8506    0.8506    0.8506        87
   <fabrication>     0.0000    0.0000    0.0000         3
       <formula>     0.9716    0.9746    0.9731       631
          <name>     0.9402    0.9665    0.9532       179
         <shape>     0.9726    0.9467    0.9595        75
     <substrate>     0.6667    1.0000    0.8000         4
         <value>     0.9366    0.9505    0.9435       202
      <variable>     0.9899    0.9899    0.9899       198

all (micro avg.)     0.9532    0.9608    0.9570      1379

----------------------------------------------------------------------

** Worst ** model scores - run 2
                  precision    recall  f1-score   support

        <doping>     0.8764    0.8966    0.8864        87
   <fabrication>     0.2000    0.3333    0.2500         3
       <formula>     0.9625    0.9762    0.9693       631
          <name>     0.9543    0.9330    0.9435       179
         <shape>     0.9861    0.9467    0.9660        75
     <substrate>     0.5000    1.0000    0.6667         4
         <value>     0.9458    0.9505    0.9481       202
      <variable>     0.9899    0.9899    0.9899       198

all (micro avg.)     0.9532    0.9608    0.9570      1379


** Best ** model scores - run 3
                  precision    recall  f1-score   support

        <doping>     0.8125    0.8966    0.8525        87
   <fabrication>     0.3333    0.3333    0.3333         3
       <formula>     0.9809    0.9762    0.9786       631
          <name>     0.9722    0.9777    0.9749       179
         <shape>     0.9730    0.9600    0.9664        75
     <substrate>     0.6667    1.0000    0.8000         4
         <value>     0.9606    0.9653    0.9630       202
      <variable>     0.9899    0.9899    0.9899       198

all (micro avg.)     0.9633    0.9695    0.9664      1379

----------------------------------------------------------------------

Average over 10 folds
                  precision    recall  f1-score   support

        <doping>     0.8487    0.8782    0.8629        87
   <fabrication>     0.0743    0.1333    0.0894         3
       <formula>     0.9733    0.9751    0.9742       631
          <name>     0.9608    0.9670    0.9638       179
         <shape>     0.9638    0.9493    0.9564        75
     <substrate>     0.6576    0.9750    0.7766         4
         <value>     0.9528    0.9584    0.9556       202
      <variable>     0.9894    0.9899    0.9896       198

all (micro avg.)     0.9575    0.9644    0.9609          

model config file saved
preprocessor saved
model saved
